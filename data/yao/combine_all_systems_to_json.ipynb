{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from string import punctuation\n",
    "\n",
    "original_sentences = []\n",
    "simplified_sentences = []\n",
    "\n",
    "def remove_tokenization_artifacts(s, src):\n",
    "    stokens = s.split()\n",
    "    snew = s\n",
    "    for i, token in enumerate(stokens):\n",
    "        if i > 0 and i < len(stokens) - 1 and token in punctuation:\n",
    "            substrboth = stokens[i - 1] + token + stokens[i + 1]\n",
    "            substrleft = stokens[i - 1] + token\n",
    "            substright = token + stokens[i + 1]\n",
    "            if substrboth in src:\n",
    "                snew = snew.replace(stokens[i - 1] + \" \" + token + \" \" + stokens[i + 1], substrboth)\n",
    "            elif substrleft in src:\n",
    "                snew = snew.replace(stokens[i - 1] + \" \" + token, substrleft)\n",
    "            elif substright in src:\n",
    "                snew = snew.replace(token + \" \" + stokens[i + 1], substright)\n",
    "\n",
    "    snew = snew.replace(\"''\", '\"')\n",
    "    snew = snew.replace(\" .\", \".\")\n",
    "    snew_rest = \"\" if len(snew) == 1 else snew[1:]\n",
    "    if len(snew) > 0:\n",
    "        snew = snew[0].capitalize() + snew_rest\n",
    "    snew = snew.replace(\"-lrb-\", \"(\").replace(\"-rrb-\", \")\")\n",
    "    snew = snew.replace(\"-LRB-\", \"(\").replace(\"-RRB-\", \")\")\n",
    "    return snew\n",
    "\n",
    "\n",
    "# read ./systems/asset.test.orig\n",
    "with open(\"systems/asset.test.orig\") as f:\n",
    "    sentences = [sentence.strip() for sentence in f.readlines()]\n",
    "    original_sentences = sentences\n",
    "\n",
    "outputs_dict = {}\n",
    "\n",
    "# read each file in systems directory\n",
    "for file in glob.glob(\"systems/*\"):\n",
    "    if file == \"systems/three_new_systems_input.json\":\n",
    "        continue\n",
    "    # read the file by line\n",
    "    with open(file) as f:\n",
    "        # get the system name from file\n",
    "        # system = file.split(\"/\")[-1]\n",
    "        sentences = f.readlines()\n",
    "        # remove newline character from each line\n",
    "        sentences = [sentence.strip() for sentence in sentences]\n",
    "        for i, simplified in enumerate(sentences):\n",
    "            original_sentence = original_sentences[i]\n",
    "            if original_sentence not in outputs_dict:\n",
    "                outputs_dict[original_sentence] = {}\n",
    "            outputs_dict[original_sentence][file] = remove_tokenization_artifacts(simplified, original_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# save outputs_dict to json file\n",
    "with open(\"18_systems_dict.json\", \"w\") as f:\n",
    "    json.dump(outputs_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('paraphrase')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51d4b053945bb951b16f24566ff3322f1cf2f2e71937c6e2fa134fa8352168a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
